		Gfarm File System Installation Manual

About this document
===================

This document describes the installation and configuration of Gfarm
file system by RPM binary packages.

About Gfarm file system
=======================

Gfarm file system is a virtual file system (cluster/Grid file system)
consisting of a metadata server and many file system nodes.  It is a
network shared file system like NFS or AFS in the user's view; and
besides, it provides scalable I/O performance.

Unique feature of Gfarm is that each file system node is also a client
to the Gfarm file system.  Distributed access by file system nodes
realizes super-scalable I/O performance.

Configuration of Gfarm metadata server
======================================

o (For wide area use) Installation of host certificate

(This section is not necessary for internal use within trusted local
area network including a virtual private network or within a PC
cluster.)

For wide area use, Gfarm uses Grid security infrastructure (GSI) for
authentication and authorization between a client and a metadata
server.  It is necessary to obtain a host certificate signed by an
appropriate Certificate Authority (CA).

You can use your own CA, or, for example, one of CAs for ApGrid
testbed listed in the following URL.

	https://www.apgrid.org/CA/CertificateAuthorities.html
	
Signed host certificate and the corresponding secret key need to be
stored at /etc/grid-security/host{cert,key}.pem.  Trusted CA
certificate needs to be stored in /etc/grid-security/certificates.

For authorization, it is necessary to set up the
/etc/grid-security/grid-mapfile file that includes a list of mappings
between a subject name of user certificate and a UNIX user name.  For
details in GSI, refer to http://www.globus.org/security/.

o Installation by Gfarm RPM binary packages

Install RPM packages for Gfarm metadata server.

	# rpm -Uvh gfarm-gsi-server-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-libs-X.X.X-X.ARCH.rpm

Note: It is possible to set up client configuration on the metadata
      server.  It is just omitted in this document for simplicity.

o Configuration of Gfarm file system

Run 'config-gfarm' to configure a Gfarm file system.  At first, make
sure the default setting with the -t option.  With the -t option,
nothing is really executed except displaying the setting for
configuration.

	# config-gfarm -t
	prefix [--prefix]: 
	domain name  [-d]: example.com
	openldap version    [-V]: 2.1
	metadata directory  [-l]: /var/gfarm-ldap
	metaserver hostname [-h]: metadb.example.com
	slapd port [-p]: 389
	gfmd port  [-m]: 601
	gfsd port  [-s]: 600
	slapd DB cache size [-c]: 536870912 bytes
	slapd DB type ($SLAPD_DB): bdb

You can modify any default parameter by the option shown in [ ].  For
example, to change the port for slapd because there is another LDAP
server running, you can change the port by the -p option.

	# config-gfarm -t -p 10389

'prefix' is used to configure several Gfarm file systems or to
configure it in user privilege. It makes all configuration files
generated under the specified directory.
Note that if you want to use Gfarm in user privilege, you have to
specify 1024 or higher values as the port numbers.

Note: If you are using an openldap server version 2.0 series or
      earlier, we strongly recommend to use the version 2.1 series or
      later.  Otherwise, file names in Gfarm file system will be
      case-insensitive.

When you confirm the parameter, run 'config-gfarm' without the -t
option.

	# config-gfarm -p 10389

config-gfarm set up the metadata directory that keeps file system
metadata, creates a Gfarm configuration file %%SYSCONFDIR%%/gfarm.conf, and
executes slapd (LDAP server) and gfmd.

If the metadata directory or the configuration file already exists,
config-gfarm fails.  You can rename the file or directory before
running config-gfarm, or execute config-gfarm with the -f option.
With the -f option, config-gfarm deletes and creates a new metadata
directory and/or a configuration file.

Created %%SYSCONFDIR%%/gfarm.conf assumes security in the cluster or LAN
environment.  For further information, refer to the man page of
gfarm.conf.

Configuration of Gfarm file system node (and client node)
=========================================================

o (For wide area use) Installation of host certificate

(This section is not necessary for internal use within trusted local
area network including a virtual private network or within a PC
cluster.)

likewise in the metadata server section.

o Installation by Gfarm RPM binary packages

Install RPM packages for Gfarm file system node.

	# rpm -Uvh gfarm-gsi-fsnode-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-libs-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-client-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-doc-X.X.X-X.ARCH.rpm

Since each file system node is usually a client node, it is necessary
to install a client package.  Document package is optional.

Moreover, to enable existing binary applications to access to Gfarm
file system as a client node, install glibc-not-hidden package.

	# rpm -Uvh glibc-not-hidden-X.X.X-X.ARCH.rpm

o Configuration of file system node

Copy %%SYSCONFDIR%%/gfarm.conf from the metadata server that is created by
'config-gfarm' as described in the previous section.  For example,
when the metadata server is 'metadb.example.com', you can copy it from
the server using scp.

	# scp -p metadb.example.com:%%SYSCONFDIR%%/gfarm.conf /etc

Note: The location of the Gfarm configuration file can be specified by
      'prefix' of config-gfsd as described below.

Run 'config-gfsd' to set up a spool directory in a local file system
on the file system node, and to register to the metadata server.  At
first, make sure the default setting with the -t option.  With the -t
option, nothing is really executed except displaying the setting for
configuration.  The following example specifies /var/spool/gfarm as a
spool directory.

	# config-gfsd -t /var/spool/gfarm
	prefix [--prefix]: 
	hostname     [-h]: linux-1.example.com
	architecture [-a]: i386-fedora3-linux
	ncpu         [-n]: 2
	spool directory  : /var/spool/gfarm

You can modify any default parameter by the option shown in [ ].  Note
that the spool directory should be a non-shared area among file system
nodes.

Note: When 'prefix' is specified, it is possible to change the
      location of the Gfarm configuration file to
      <prefix>/etc/gfarm.conf.  In this case, every user needs to
      create ~/.gfarmrc in their home directory.

		% ln -s <prefix>/etc/gfarm.conf ~/.gfarmrc

When you confirm the parameter, run 'config-gfsd' without the -t
option.

	# config-gfsd /var/spool/gfarm

config-gfsd initializes the spool directory, updates the Gfarm
configuration file for the file system node, and executes gfsd.

If the spool directory already exists, config-gfsd fails.  You can
move the directory before running config-gfsd, or execute config-gfsd
with the -f option.  With the -f option, config-gfsd deletes and
creates a new spool directory.

Configuration of Gfarm client node
==================================

This chapter describes configuration for only client node.

o Installation by Gfarm RPM binary packages

Install RPM packages for Gfarm client node.

	# rpm -Uvh gfarm-gsi-client-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-libs-X.X.X-X.ARCH.rpm \
		   gfarm-gsi-doc-X.X.X-X.ARCH.rpm

Document package is optional.

To enable existing binary applications to access to Gfarm file system,
install glibc-not-hidden package.

	# rpm -Uvh glibc-not-hidden-X.X.X-X.ARCH.rpm

o Configuration of client node

Copy %%SYSCONFDIR%%/gfarm.conf from the metadata server to the client node.  For
example, when the metadata server is 'metadb.example.com', you can copy
it from the server using scp.

	# scp -p metadb.example.com:%%SYSCONFDIR%%/gfarm.conf /etc

Note: This setting can be substituted for copying to ~/.gfarmrc as
      described in the next chapter.

Setting for each user
=====================

o (GSI only) Installation of user certificate

(This set up is only necessary for GSI.)

You need to obtain a user certificate signed by an appropriate CA, as
described in the section "installation of host certificate".  Signed
user certificate and the corresponding secret key need to be stored at
~/.globus/user{cert,key}.pem.  Trusted CA certificate needs to be
stored in /etc/grid-security/certificates.

o Configuration of client node

(This section is not necessary when %%SYSCONFDIR%%/gfarm.conf exists.)

Copy %%SYSCONFDIR%%/gfarm.conf from the metadata server to ~/.gfarmrc on the
client node.  For example, when the metadata server is
'metadb.example.com', you can copy it from the server using scp.

	# scp -p metadb.example.com:%%SYSCONFDIR%%/gfarm.conf ~/.gfarmrc

o Creation of a home directory in Gfarm file system

Before everything, you need to create a home directory in the Gfarm
file system.

	% gfmkdir gfarm:~

The home directory needs to be created only once by any client since
it is shared by every client.  You do not need to create the home
directory more than once.

If this command fails, slapd on the metadata server is not executed
correctly, or the Gfarm configuration file (~/.gfarmrc or
%%SYSCONFDIR%%/gfarm.conf) on the client is not correct.

o LD_PRELOAD environment variable

Existing dynamically linked executables on every client node can
access the Gfarm file system by specifying LD_PRELOAD environment
variable. Please look at README.hook.en for detail.

When the login shell is bash, add the following to .bashrc,

	LD_PRELOAD='/usr/lib/libgfs_hook.so.0 /usr/lib/gfarm/libpthread-not-hidden.so /usr/lib/gfarm/libc-not-hidden.so'
	export LD_PRELOAD

When the login shell is csh or tcsh, add the following to .cshrc,

	setenv LD_PRELOAD '/usr/lib/libgfs_hook.so.0 /usr/lib/gfarm/libpthread-not-hidden.so /usr/lib/gfarm/libc-not-hidden.so'

Test of Gfarm file system
=========================

You can check whether the Gfarm file system works or not by any client
since it can be accessed (or shared) by every client node.

o (only GSI) Creation of a user proxy certificate

(This set up is only necessary for GSI.)

Run 'grid-proxy-init' to create a user proxy certificate.  It is
included in the Globus toolkit.

	% grid-proxy-init

For details in Globus toolkit, refer to http://www.globus.org/

o gfls - directory listing

'gfls' lists the contents of a directory.

	% gfls -la
	drwxr-xr-x tatebe   *                 0 Dec 23 23:39 .
	drwxrwxrwx root     gfarm             0 Jan  1  1970 ..

o gfhost - file system node information

'gfhost -M' displays the information of file system nodes registered
in the metadata server.

	% gfhost -M
	i386-fedora3-linux 2 linux-1.example.com
	i386-fedora3-linux 2 linux-2.example.com
	i386-fedora3-linux 2 linux-3.example.com
	sparc-sun-solaris8 1 solaris-1.example.com
	sparc-sun-solaris8 1 solaris-2.example.com
	...

'gfhost -l' displays the status of file system nodes.

	% gfhost -l
	0.01/0.03/0.03 s i386-fedora3-linux 2 linux-1.example.com(10.0.0.1)
	0.00/0.00/0.00 s i386-fedora3-linux 2 linux-2.example.com(10.0.0.2)
	-.--/-.--/-.-- - i386-fedora3-linux 2 linux-3.example.com(10.0.0.3)
	0.10/0.00/0.00 G sparc-sun-solaris8 1 solaris-1.example.com(10.0.1.1)
	x.xx/x.xx/x.xx - sparc-sun-solaris8 1 solaris-2.example.com(10.0.1.2)
	...

The second field shows the status of authentication to the file system
node.  's', 'g', and 'G' show successful authentication, while 'x'
shows the authentication failure.

'-.--/-.--/-.--' in the first field shows that gfsd is not executed
correctly, and 'x.xx/x.xx/x.xx' shows the file system node is probably
down.

o gfps - process information

'gfps' shows the process information by accessing gfmd on the metadata
server.

	% gfps

gfps exits immediately without any message if gfmd is correctly
executed.

For details of the above Gfarm commands, refer to each man page.

Access from existing applications
=================================

To enable the setting of LD_PRELOAD in the section "Setting for each
user", log in again, or, set the LD_PRELOAD environment variable.

	% echo $LD_PRELOAD
	/usr/lib/libgfs_hook.so.0 /usr/lib/gfarm/libpthread-not-hidden.so /usr/lib/gfarm/libc-not-hidden.so

After that, every program can access the Gfarm file system as if it
is mounted on /gfarm.

	% ls -l /gfarm

Note: A file in the Gfarm file system can be specified by a Gfarm URL
      starting with 'gfarm:', or a path name under /gfarm.  There are
      the following relationship between the Gfarm URL and the path
      name;
		root directory      gfarm:/ = /gfarm
		home directory      gfarm:~ = /gfarm/~
		current directory   gfarm:  = /gfarm/.

Home directory in the Gfarm file system can be specified by /gfarm/~

	% cp .bashrc /gfarm/~/
	% ls -la /gfarm/~

When you would like to access Gfarm file system via the interactive
shell, it is necessary to re-run the shell after setting the
LD_PRELOAD environment.  After that, you can run 'cd' and enable
filename completion.

	% bash
	% cd /gfarm/~
	% ls -la
	% pwd

Further example in advanced functionality
=========================================

o File replica creation

Each file in the Gfarm file system can have several file copies that
can be stored on two and more file system nodes.

Multiple file copies of the same file enables to access the file even
when one of the file system nodes is down.  Moreover, it enables to
prevent access performance deterioration by accessing different file
copies.

'gfwhere' command displays the location of file copies, or replica
catalog, of the specified files.

	% gfwhere .bashrc
	0: linux-1.example.com

'gfrep' command creates file copies.  For example, 'gfrep -N 2'
creates two file copies.

	% gfrep -N 2 .bashrc
	% gfwhere .bashrc
	0: linux-1.example.com linux-2.example.com

In this case, '.bashrc' has two copies; one is stored on
linux-1.example.com and the other is stored on linux-2.example.com.

When the directory is specified, file copies will be created in all
files under the directory.  For example, when you would like to create
at least two file copies for all files under the home directory in the
Gfarm file system, run

	% gfrep -N 2 gfarm:~

o Parallel and distributed processing

Since the Gfarm file system can be shared among every client node,
multiple processes running on different nodes can share the same file
system.  Distributed make with several parallelism is one of examples
of parallel and distributed processing.

Moreover, further high-performance file access can be realized by the
unique feature of Gfarm such that each file system node is also a
client node.  Key idea is 'moving the program to the data' and
'executing the program on the node that has the data'.  'gfrun' is a
remote process execution command with this 'file-affinity' process
scheduling.

The following example executes 'grep' (an existing application) on the
node where the target file 'gfarm:target_file' is stored.

	% gfrun grep target_string gfarm:target_file

gfrun automatically selects the least busy node among nodes that have
a file copy of 'target_file', and execute grep on the node.

You can execute gfrun in parallel for parallel and distributed
processing.

Besides, it is possible to execute grep itself in parallel, or,
"parallel grep".  For parallel execution, a target file needs to be
divided and stored on multiple nodes.  The following example shows the
case such that 'textfile' is divided into 5 fragments and stored to
'gfarm:input'.

	% gfsched -N 5 | gfimport_text -H - -o gfarm:input textfile

Note: Gfarm commands stating with 'gf' access files in Gfarm file
      system by a Gfarm URL staring with 'gfarm:'.  A path name such
      as /gfarm/~/foo cannot be used by Gfarm commands.

'gfimport_text' is a utility program to divide a text file into
multiple fragments by the line and store to a file specified by the -o
option.  Each file fragment has almost the same size.

In this case, for example, 'gfarm:input' is divided into 5 fragments,
and stored on different nodes from linux-1.example.com to
linux-5.example.com.

	% gfwhere gfarm:input
	0: linux-1.example.com
	1: linux-2.example.com
	2: linux-3.example.com
	3: linux-4.example.com
	4: linux-5.example.com

Note that the file can be accessed normally even though it is
physically divided.

	% diff gfarm:input textfile

At this time, when you execute grep via gfrun as described above, grep
is executed in parallel on nodes that have a copy of the file
fragment.  Each grep command searches 'target_string' from each file
fragment.

	% gfrun grep target_string gfarm:input

When the -o option is specified in gfrun, the standard output can be
redirected to the specified file.

	% gfrun -o gfarm:output grep target_string gfarm:input

For details, refer to gfrun manual page.

$Id$
